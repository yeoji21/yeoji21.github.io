---
title: "[R]기말 정리"
author: "yeoji21"
date: 2021-12-05
categories: [bigdata, R]
tags: [data, bigdata, r]
---

### 문제 1. gapminder 라이브러리를 이용하여 다음 질문에 답하라. (R로 작성한 코드와 실행결과를 제시)

#### 1) gapminder 데이터 프레임의 구성 항목을 조회해보고 설명하라


```r
> install.packages("gapminder")
trying URL 'https://cran.rstudio.com/bin/macosx/contrib/4.1/gapminder_0.3.0.tgz'
Content type 'application/x-gzip' length 2031864 bytes (1.9 MB)
==================================================
downloaded 1.9 MB
The downloaded binary packages are in
	/var/folders/0w/vr0g48zx0z5bhnzwf1d7py680000gn/T//RtmpGtR8mN/downloaded_packages
> library(gapminder)
> gapminder
# A tibble: 1,704 × 6
   country     continent  year lifeExp      pop gdpPercap
   <fct>       <fct>     <int>   <dbl>    <int>     <dbl>
 1 Afghanistan Asia       1952    28.8  8425333      779.
 2 Afghanistan Asia       1957    30.3  9240934      821.
 3 Afghanistan Asia       1962    32.0 10267083      853.
 4 Afghanistan Asia       1967    34.0 11537966      836.
 5 Afghanistan Asia       1972    36.1 13079460      740.
 6 Afghanistan Asia       1977    38.4 14880372      786.
 7 Afghanistan Asia       1982    39.9 12881816      978.
 8 Afghanistan Asia       1987    40.8 13867957      852.
 9 Afghanistan Asia       1992    41.7 16317921      649.
10 Afghanistan Asia       1997    41.8 22227415      635.
# … with 1,694 more rows
> str(gapminder)
tibble [1,704 × 6] (S3: tbl_df/tbl/data.frame)
 $ country  : Factor w/ 142 levels "Afghanistan",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ continent: Factor w/ 5 levels "Africa","Americas",..: 3 3 3 3 3 3 3 3 3 3 ...
 $ year     : int [1:1704] 1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...
 $ lifeExp  : num [1:1704] 28.8 30.3 32 34 36.1 ...
 $ pop      : int [1:1704] 8425333 9240934 10267083 11537966 13079460 14880372 12881816 13867957 16317921 22227415 ...
 $ gdpPercap: num [1:1704] 779 821 853 836 740 ...
```
- country : factor with 142 levels
- continent : factor with 5 levels
- year : ranges from 1952 to 2007 in increments of 5 years
- lifeExp : life expectancy at birth, in years
- pop : population
- gdpPercap : GDP per capita (US$, inflation-adjusted)

#### 2) gapminder 데이터에서 각 대륙의 연도별 gdpPercap의 평균값을 플롯하고 범례를 추가하라
```r
> library(dplyr)
> library(ggplot2)
> groupedData = gapminder%>%group_by(year, continent)%>%summarise(avg_gdpPercap = mean(gdpPercap))
`summarise()` has grouped output by 'year'. You can override using the `.groups` argument.
> groupedData
# A tibble: 60 × 3
# Groups:   year [12]
    year continent avg_gdpPercap
   <int> <fct>             <dbl>
 1  1952 Africa            1253.
 2  1952 Americas          4079.
 3  1952 Asia              5195.
 4  1952 Europe            5661.
 5  1952 Oceania          10298.
 6  1957 Africa            1385.
 7  1957 Americas          4616.
 8  1957 Asia              5788.
 9  1957 Europe            6963.
10  1957 Oceania          11599.
# … with 50 more rows
> ggplot(groupedData, aes(x=year, y=avg_gdpPercap, col=continent)) + geom_point()
```

#### 3) gapminder 데이터에서 1인당 gdp에 따른 기대수명을 대륙별로 살펴볼 수 있는 그래프를 작성하라
```r
> gapminder%>%group_by(continent)%>%ggplot(aes(x=gdpPercap, y=lifeExp, col=continent))+geom_point(alpha=0.4)
```
<!-- ```r
> data = gapminder%>%group_by(continent)%>%summarise(gdp_mean=mean(gdpPercap), life=mean(lifeExp))
> data
# A tibble: 5 × 3
  continent gdp_mean  life
  <fct>        <dbl> <dbl>
1 Africa       2194.  48.9
2 Americas     7136.  64.7
3 Asia         7902.  60.1
4 Europe      14469.  71.9
5 Oceania     18622.  74.3
> ggplot(data, aes(x=gdp_mean, y=life, col=continent)) + geom_bar(stat = "identity", aes(fill=continent))
``` -->

#### 4) gapminder 데이터에서 2007년 아시아 대륙의 인구분포를 순위별로 볼 수 있는 그래프를 작성하라.
```r
> gapminder%>%filter(year==2007 & continent=="Asia")%>%ggplot(aes(reorder(country, pop), pop))+geom_bar(stat="identity")+coord_flip()
```

#### 5) gapminder 데이터에서 2007년도 전 세계의 기대수명의 분포 특성을 보여주는 그래프를 작성하라
```r
> gapminder%>%filter(year==2007)%>%ggplot(aes(lifeExp))+geom_histogram()
```

#### 6) gapminder 데이터에서 대륙별로 기대수명의 분포 특성을 보여주는 그래프를 작성하라
```r
gapminder%>%group_by(continent)%>%ggplot(aes(continent, lifeExp))+geom_boxplot()
```

#### 7) gapminder 데이터에서 대륙이 아시아일 때, 국가별 기대 수명을 보여주는 막대 그래프를 작성하라.
```r
> gapminder%>%filter(continent=="Asia")%>%ggplot(aes(country, lifeExp))+geom_bar(stat="identity") + coord_flip()
```

#### 8) gapminder 데이터에서 1952년 한국의 기대수명, 인구 수, 1인당 국민 총생산은 얼마인가?
```r
> gapminder%>%filter(country=="Korea, Rep.", year==1952)
# A tibble: 1 × 6
  country     continent  year lifeExp      pop gdpPercap
  <fct>       <fct>     <int>   <dbl>    <int>     <dbl>
1 Korea, Rep. Asia       1952    47.5 20947571     1031.
```

#### 9) gapminder 데이터에서 1952년 이후 연도별 한국의 인구 수와 1인당 국민 총생산을 시각화하는 그래프를 작성하라.
```r
> gapminder%>%filter(country=="Korea, Rep.", year>1952)%>%ggplot(aes(pop, gdpPercap, col=year)) + geom_point()+geom_line()
```

#### 10) gapminder 데이터에서 연도별 국내총생산(gdp)을 계산하여 한국과 쿠웨이트의 gdp 변화를 같은 그래프에 표시하는 그래프를 작성하라.
```r
gapminder%>%filter(country=="Korea, Rep." | country=="Kuwait")%>%mutate(gdp=gdpPercap*pop)%>%ggplot(aes(year, gdp, col=country)) + geom_point() + geom_line()
```

### 문제 2. cars 데이터를 사용하여 다음 질문에 답하시오

#### 1) cars 데이터에서 20, 22, 23번째 샘플을 제거하여 cars1에 저장하시오.
```r
> cars1 = cars[-c(20, 22, 23), ]
> cars1
   speed dist
1      4    2
2      4   10
3      7    4
4      7   22
5      8   16
6      9   10
7     10   18
8     10   26
9     10   34
10    11   17
11    11   28
12    12   14
13    12   20
14    12   24
15    12   28
16    13   26
17    13   34
18    13   34
19    13   46
21    14   36
24    15   20
```

#### 2) cars1 데이터에 speed=26, dist=100이라는 샘플을 추가하여 cars2에 저장하시오.
```r
> cars2 = rbind(cars1, list(26, 100))
> cars2
...
```

#### 3) 새로운 데이터 cars2를 훈련 집합으로 선형 회귀 모형을 구하시오.
```r
> car_model = lm(dist~speed, data=cars2)
> car_model

Call:
lm(formula = dist ~ speed, data = cars2)

Coefficients:
(Intercept)        speed  
    -21.037        4.102  
```

#### 4) 훈련집합 데이터와 선형 회귀 모형을 하나의 그래프로 나타내시오.
```r
> plot(cars2)
> abline(car_model, col='red')
```

#### 5) 이 데이터(cars2)에 대한 통계량을 분석하고, 원래 cars 데이터와 비교하여 해석하시오.
```r
> cars_model = lm(formula = dist ~ speed, data = cars)
> summary(cars_model)

Call:
lm(formula = dist ~ speed, data = cars)

Residuals:
    Min      1Q  Median      3Q     Max 
-29.069  -9.525  -2.272   9.215  43.201 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) -17.5791     6.7584  -2.601   0.0123 *  
speed         3.9324     0.4155   9.464 1.49e-12 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 15.38 on 48 degrees of freedom
Multiple R-squared:  0.6511,	Adjusted R-squared:  0.6438 
F-statistic: 89.57 on 1 and 48 DF,  p-value: 1.49e-12

> cars2_model = lm(formula = dist ~ speed, data = cars2)
> summary(cars2_model)

Call:
lm(formula = dist ~ speed, data = cars2)

Residuals:
    Min      1Q  Median      3Q     Max 
-28.999  -8.770  -1.185   7.748  42.593 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -21.037      6.096  -3.451  0.00121 ** 
speed          4.102      0.366  11.208 9.57e-15 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 14.04 on 46 degrees of freedom
Multiple R-squared:  0.732,	Adjusted R-squared:  0.7261 
F-statistic: 125.6 on 1 and 46 DF,  p-value: 9.574e-15
```

먼저 cars의 모델인 cars_model의 speed계수는 p-value가 1.49e-12이고, cars2의 모델인 cars2_model의 speed계수 p-value는 9.57e-15로 두 모델의 p-value 모두 매우 작은 값을 가지기 때문에 회귀 계수가 유의미하다는 것을 나타낸다. 

하지만 이 모델이 데이터를 얼마나 잘 설명하는지 나타내는 Multiple R-squared 값을 보면, cars_model이 약 65%, cars2_model이 약 73%이므로, cars2_model이 좀 더 나은 모델이라고 볼 수 있다.

### 문제 3. 영희는 물체의 무게를 달리하면서 전기 자극을 따라서 물체의 이동거리를 측정하는 실험을 하였다. 영희는 전기량을 x, 물체의 무게를 u, 물체의 이동거리를 y 변수로 표현하기로 했다. 일곱 번 흑정 실험을 하여 다음 훈련집합을 구성하였다. 이 훈련 집합으로 이 절(7장 6절, 7절)의 전체 과정을 재현하라. R로 작성된 코드와 실행 결과, 가능하면 설명까지 제시하시오.

#### 1) 3차원 그래프로 데이터의 분포를 확인해보시오
```r
> install.packages("scatterplot3d")
> library(scatterplot3d)
> x = c(3.0, 6.0, 3.0, 6.0, 7.5, 7.5, 15.0)
> u = c(10.0, 10.0, 20.0, 20.0, 5.0, 10.0, 12.0)
> y = c(4.65, 5.9, 6.7, 8.02, 7.7, 8.1, 6.1)
> scatterplot3d(x, u, y, xlim=2:16, ylim=4:21, zlim=0:10, pch=20, type='h')
```

#### 2) 다중 선형 회귀모형을 구하시오.
```r
> m = lm(y~x+u)
> coef(m)
(Intercept)           x           u 
 5.79746809  0.05717624  0.04417544
```
다중 선형 회귀 또한 단순 선형 회귀와 마찬가지로 lm 함수를 사용하는데, 단지 수식을 y~x+u처럼 써서 x와 u를 설명 변수로 지정하면 된다.

이 모델을 통해 구한 최적 모델은 `y = 0.05717624x + 0.04417544u + 5.79746809`이다. 

#### 3) 훈련집합 데이터와 학습된 모델을 하나의 그래프로 그리시오.
```r
> s = scatterplot3d(x, u, y, xlim=2:16, ylim=4:21, zlim=0:10, pch=20, type='h')
> s$plane3d(m)
```

#### 4) 새로운 데이터 2개 (7.5, 15.0)과 (5.0, 12.0)에 대해 물체의 이동거리를 예측하시오. 그리고 예측 결과를 3차원 그래프로 보여주시오. 
```r
> newX = c(7.5, 5.0)
> newU = c(15.0, 12.0)
> newData = data.frame(x=newX, u=newU)
> newY = predict(m, newData)
> newY
       1        2 
6.888922 6.613455 
> s = scatterplot3d(newX, newU, newY, xlim=2:16, ylim=4:21, zlim=0:10, pch=20, type='h', color='red', angle=60)
> s$plane3d(m)
```

### 문제 4. 미국의 유명대학 UCLA의 IDRE는 데이터 분석을 도와주는 기관이다. 이 기관에서 제공하는 UCLA 대학원 입학 관련 UCLA admission 데이터를 이용하여 다음 물음들에 답하시오.

#### 1) UCLA admission 데이터를 읽어오는 코드를 작성하시오.
```r
> ucla = read.csv('https://stats.idre.ucla.edu/stat/data/binary.csv')
```

#### 2) UCLA admission 데이터 구조를 확인하고, 변수들의 의미를 간략하게 기술하고, 이들 변수들 중에 어떤 변수들이 설명 변수이고 어떤 변수가 반응변수인지 구분하시오.
```r
> str(ucla)
'data.frame':	400 obs. of  4 variables:
 $ admit: int  0 1 1 1 0 1 1 0 1 0 ...
 $ gre  : int  380 660 800 640 520 760 560 400 540 700 ...
 $ gpa  : num  3.61 3.67 4 3.19 2.93 3 2.98 3.08 3.39 3.92 ...
 $ rank : int  3 3 1 4 4 2 1 2 3 2 ...
 > levels(factor(ucla$rank))
[1] "1" "2" "3" "4"
```
str 함수를 실행한 결과, 400개의 샘플이 있고 각 샘플은 4개의 변수를 가졌음을 알 수 있다.

- admit : 합격 여부를 의미한다. 불합격은 0, 합격은 1
- gre : 미국 대학원 수학능력시험인 gre의 점수
- gpa : 학부 성적(평균 학점)
- rank : 출신 대학 순위를 나타낸다. levels로 확인한 결과 [1, 2, 3, 4]의 4개값으로 이루어진 것을 알 수 있다.

이 중에서 설명 변수는 gre, gpa, rank이고 반응 변수는 admit이다. 

#### 3) UCLA admission 데이터를 각 설명변수와 반응변수 간의 분포를 시각화하시오.
```r
> plot(ucla)
```
plot 함수를 통해 4개 변수 사이으이 상관 관계를 확인할 수 있다. 이 그래프를 보면 gre가 높을수록 admit이 1에 가까운 것을 알 수 있다.

하지만 이 그림에서는 400개의 샘플을 작은 공간에 그리다보니 여러 개의 점이 겹쳐 데이터의 분포를 제대로 확인할 수 없다. 따라서 ggplot2를 설명변수와 반응변수의 분포를 좀 더 정교하게 시각화를 시도해보자.

먼저 gre와 admit 변수간의 분포이다.
```r
> ucla%>%ggplot(aes(gre, admit)) + geom_jitter(aes(col=factor(admit)), height=0.1, width=0.0)
```
이 그래프는 admit 변수에 약간의 잡음을 추가(geom_jitter())하여 샘플을 구별할 수 있게한 뒤, admit을 범주형으로 바꾼 뒤 col 옵션으로 색을 구분하였다. height 옵션으로 수직 방향의 잡음 정도를 10%로 설정하고 width로 수평 방향의 gre 변수에는 잡음을 제거하였다. 

같은 방식으로 설명 변수인 gre, gpa, rank와 admit의 분포 관계를 gridExtra 라이브러리를 통해 한 행에 3개의 그림으로 나타내면 다음과 같다. 

```r
> library(gridExtra)
> gre_p = ucla%>%ggplot(aes(gre, admit)) + geom_jitter(aes(col=factor(admit)), height=0.1, width=0.0)
> gpa_p = ucla%>%ggplot(aes(gpa, admit)) + geom_jitter(aes(col=factor(admit)), height=0.1, width=0.0)
> rank_p = ucla%>%ggplot(aes(rank, admit)) + geom_jitter(aes(col=factor(admit)), height=0.1, width=0.1)
> grid.arrange(gre_p, gpa_p, rank_p, ncol=3)
```

#### 4) 로지스틱 회귀모델을 적용하여 모델링을 수행하고, 최적 모델을 도출하시오. 
```r
> m = glm(admit~., data=ucla, family=binomial)
> coef(m)
(Intercept)         gre         gpa        rank 
-3.44954840  0.00229396  0.77701357 -0.56003139 
```
최적 모델은 다음과 같다.  
`admit = 0.00229396*gre +  0.77701357*gpa - 0.56003139*rank  -3.44954840`

#### 5) 새로운 학생이 지원하였는데, gre가 400점,  gpa가 3.5, rank가 2이었다면, 합격 확률을 예측해보시오.
 
```r
> newStu = data.frame(gre=c(400), gpa=c(3.5), rank=c(2))
> predict(m, newdata=newStu, type='response')
        1 
0.2824219 
```
합격 활률은 28.24219%이다.

#### 6) 위의 5)문제에서 rank를 1, 2, 3, 4f로 바꾸어 가면서 합격 확률을 출력하는 프로그램을 작성하시오. 네 줄을 나열하는 프로그램과 for문을 사용한 프로그램을 각각 제시해보시오.

4줄 나열 프로그램
```r
> predict(m, newdata=data.frame(gre=c(400), gpa=c(3.5), rank=c(1)), type='response')
        1 
0.4079495 
> predict(m, newdata=data.frame(gre=c(400), gpa=c(3.5), rank=c(2)), type='response')
        1 
0.2824219 
> predict(m, newdata=data.frame(gre=c(400), gpa=c(3.5), rank=c(3)), type='response')
        1 
0.1835451 
> predict(m, newdata=data.frame(gre=c(400), gpa=c(3.5), rank=c(4)), type='response')
        1 
0.1137957 
```

for문으로 작성한 프로그램
```r
> for(i in 1:4){
+     print(predict(m, newdata=data.frame(gre=c(400), gpa=c(3.5), rank=c(i))
                                                ,type='response'))
+ }
        1 
0.4079495 
        1 
0.2824219 
        1 
0.1835451 
        1 
0.1137957 
```

#### 7) 위에서 사용한 원래의 UCLA admission 데이터에서는 rank 변수는 정수형이다. 이 변수를 범주형이라고 가정하고, 이 변수가 원핫 코드로 변환되는 과정을 기술하라.

UCLA admission 데이터의 rank 변수는 범주형의 순서값에 해당하고, 정수형으로 표현하였다. 이렇게 순서값에 정수를 부여하면 거리 개념과 크기 개념이 있기때문에 모델링할 수 있다. 하지만 문제의 가정처럼 rank를 범주형으로 변환하면 모델링에 사용하기 위해서는 원핫 코드로 변환해야 한다.

k개의 값을 갖는 범주형 변수는 k-1개의 숫자형 변수로 확장되어 원핫 코드로 표현된다. rank는 1, 2, 3, 4의 값을 가지므로 세 개의 비트로 표현되어 3개의 숫자형 변수로 확장된 원핫 코드는 다음과 같다.

1 -> (0, 0, 0)  
2 -> (1, 0, 0)  
3 -> (0, 1, 0)  
4 -> (0, 0, 1)  

#### 8) 원래의 rank 변수는 정수형인데 이 변수를 범주형으로 변환한 다음 모델링을 하고, 정수형일 때와 비교해 어떤 차이가 있는지 설명해보시오. 

```r
> ucla$rank = as.factor(ucla$rank)
> m = glm(admit~., data=ucla, family=binomial)
> coef(m)
 (Intercept)          gre          gpa        rank2        rank3        rank4 
-3.989979073  0.002264426  0.804037549 -0.675442928 -1.340203916 -1.551463677 
```

모델링의 결과를 보면 설명변수가 gre, gpa, rank2, rank3, rank4로 바뀐 것을 확인할 수 있다. 

### 문제 5. colon 데이터에 결정트리, 랜덤 포리스트, SVM을 적용하여 정확률을 비교해보시오. 적용시 전처리 연산으로 결측값을 제거하고, 반응 변수를 범주형으로 변환하고, 이 데이터에는 한 환자당 2개의 샘플이 포함되어 있으므로 홀수 번째 것만 추출하여 사용하기로 한다. 설명 변수는 id, study, time, etype을 제외한 11개 변수를 사용한다. 제거된 4개의 변수가 왜 제거되는지 이유도 설명해보시오. 

전처리
```r
> library(survival)
> str(colon)
'data.frame':	1858 obs. of  16 variables:
 $ id      : num  1 1 2 2 3 3 4 4 5 5 ...
 $ study   : num  1 1 1 1 1 1 1 1 1 1 ...
 $ rx      : Factor w/ 3 levels "Obs","Lev","Lev+5FU": 3 3 3 3 1 1 3 3 1 1 ...
 $ sex     : num  1 1 1 1 0 0 0 0 1 1 ...
 $ age     : num  43 43 63 63 71 71 66 66 69 69 ...
 $ obstruct: num  0 0 0 0 0 0 1 1 0 0 ...
 $ perfor  : num  0 0 0 0 0 0 0 0 0 0 ...
 $ adhere  : num  0 0 0 0 1 1 0 0 0 0 ...
 $ nodes   : num  5 5 1 1 7 7 6 6 22 22 ...
 $ status  : num  1 1 0 0 1 1 1 1 1 1 ...
 $ differ  : num  2 2 2 2 2 2 2 2 2 2 ...
 $ extent  : num  3 3 3 3 2 2 3 3 3 3 ...
 $ surg    : num  0 0 0 0 0 0 1 1 1 1 ...
 $ node4   : num  1 1 0 0 1 1 1 1 1 1 ...
 $ time    : num  1521 968 3087 3087 963 ...
 $ etype   : num  2 1 2 1 2 1 2 1 2 1 ...
 > table(is.na(colon))

FALSE  TRUE 
29646    82 
> myColon = na.omit(colon)
> table(is.na(myColon))

FALSE 
28416 
> myColon = myColon[c(TRUE, FALSE), ]
> myColon$status = factor(myColon$status)
```

**결정 트리**
```r
> library(rpart)
> r = rpart(status~rx+sex+age+obstruct+perfor+adhere+nodes+differ+extent+surg+node4, data=myColon)
> p = predict(r, myColon, type='class')
> table(p, myColon$status)
   
p     0   1
  0 319 147
  1 139 283
```
결정트리의 정확률 : 67.79%

**랜덤 포리스트**
```r
> install.packages("randomForest")
> library(randomForest)
> f = randomForest(status~rx+sex+age+obstruct+perfor+adhere+nodes+differ+extent+surg+node4, data=myColon)
> f

Call:
 randomForest(formula = status ~ rx + sex + age + obstruct + perfor +      adhere + nodes + differ + extent + surg + node4, data = myColon) 
               Type of random forest: classification
                     Number of trees: 500
No. of variables tried at each split: 3

        OOB estimate of  error rate: 37.95%
Confusion matrix:
    0   1 class.error
0 297 161   0.3515284
1 176 254   0.4093023
```
랜덤 포리스트의 정확률 : 68.29%

**SVM**
```r
> library(e1071)
> s = svm(status~rx+sex+age+obstruct+perfor+adhere+nodes+differ+extent+surg+node4, data=myColon)
> p = predict(s, myColon)
> table(p, myColon$status)
   
p     0   1
  0 364 178
  1  94 252
```
SVM의 정확률 : 69.37%

먼저 study 변수는 모든 샘플 값이 1이므로 분별력이 없는 변수이므로 제거하고, etype은 같은 환자에 대해 2와 1이 반복된다. 여기서는 홀수 번째 데이터만 사용하므로 etype도 필요없다. id 변수 또한 환자를 구분하기 위한 변수이므로 삭제한다. time같은 경우는 환자의 병이 재발한 시점과 사망한 시점까지의 일수를 기록한 것인데, 모델링의 목적은 환자가 완치할 수 있는지를 예측하는 것이므로 time 변수에 대해 모르는 상태에서 예측하는 것이 옳기 때문에 제거해야 한다.

